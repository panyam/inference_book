%%%%%%%%%%%%%%%%%%%%%%%% references04.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% References for Chapter 4: Model Formats and Quantization
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{99.}

% Model Formats
\bibitem{safetensors2023}
Hugging Face: SafeTensors: A Simple, Safe Way to Store and Distribute Tensors.
\url{https://huggingface.co/docs/safetensors/} (2023)

\bibitem{gguf2023}
Gerganov, G.: GGUF Specification.
\url{https://github.com/ggerganov/ggml/blob/master/docs/gguf.md} (2023)

\bibitem{llamacpp2024}
Gerganov, G.: llama.cpp - LLM inference in C/C++.
\url{https://github.com/ggerganov/llama.cpp} (2024)

\bibitem{onnx2024}
ONNX: Open Neural Network Exchange.
\url{https://onnx.ai/} (2024)

% Quantization Methods
\bibitem{gptq2023}
Frantar, E., Ashkboos, S., Hoefler, T., Alistarh, D.: GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers.
In: International Conference on Learning Representations (ICLR) (2023)

\bibitem{awq2024}
Lin, J., Tang, J., Tang, H., Yang, S., Dang, X., Han, S.: AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration.
In: Conference on Machine Learning and Systems (MLSys) (2024)

\bibitem{bitsandbytes2022}
Dettmers, T., Lewis, M., Belkada, Y., Zettlemoyer, L.: LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale.
In: Advances in Neural Information Processing Systems (NeurIPS) (2022)

\bibitem{qlora2023}
Dettmers, T., Pagnoni, A., Holtzman, A., Zettlemoyer, L.: QLoRA: Efficient Finetuning of Quantized LLMs.
In: Advances in Neural Information Processing Systems (NeurIPS) (2023)

% Model Families
\bibitem{llama3_2024}
Meta AI: Llama 3.2: Revolutionizing Edge AI and Vision with Open, Customizable Models.
\url{https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/} (2024)

\bibitem{mistral2023}
Jiang, A.Q., et al.: Mistral 7B. arXiv preprint arXiv:2310.06825 (2023)

\bibitem{qwen2_2024}
Bai, J., et al.: Qwen2.5 Technical Report. arXiv preprint arXiv:2412.15115 (2024)

\bibitem{phi3_2024}
Abdin, M., et al.: Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone. arXiv preprint arXiv:2404.14219 (2024)

\bibitem{gemma2024}
Gemma Team, Google DeepMind: Gemma: Open Models Based on Gemini Research and Technology. arXiv preprint arXiv:2403.08295 (2024)

% Model Repositories
\bibitem{huggingface2024}
Hugging Face: Hugging Face Hub.
\url{https://huggingface.co/models} (2024)

\bibitem{ollama2024}
Ollama: Ollama Model Library.
\url{https://ollama.com/library} (2024)

\end{thebibliography}
