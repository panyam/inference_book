%%%%%%%%%%%%%%%%%%%%%part1.tex%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Part I: Foundations
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{partbacktext}
\part{Foundations}
\label{part:foundations}

Welcome to the world of self-hosted AI inference. In this first part, you'll build a solid foundation for everything that follows.

We start with consumer-grade hardware and 7B parameter models---accessible to anyone with a modern laptop or a mid-range GPU. By the end of Part I, you'll have a working inference control plane with observability built in from day one.

\textbf{What You'll Learn:}
\begin{itemize}
\item How inference differs from training, and why it's accessible
\item Hardware fundamentals: GPUs, VRAM, and what you actually need
\item Model formats, quantization basics, and how to choose models
\item Inference engines: from Ollama to vLLM
\item Building your first Go-based control plane (v0.1)
\item Optional: Browser-based inference for zero-cost deployments
\end{itemize}

\textbf{What You'll Build:}
\begin{itemize}
\item A working inference endpoint serving a 7B model
\item A Go control plane with metrics and health checks
\item Docker deployment with Prometheus and Grafana
\item Optionally: A hybrid browser/server inference client
\end{itemize}

\textbf{Hardware Requirements:}
\begin{itemize}
\item Minimum: 16GB RAM, modern CPU (Apple M1/M2/M3, or good x86)
\item Recommended: GPU with 8GB+ VRAM (RTX 3060 12GB, RTX 4060, etc.)
\item Alternative: Cloud GPU rental (\$0.20--0.50/hour)
\end{itemize}

\end{partbacktext}
